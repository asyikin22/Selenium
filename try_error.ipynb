{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Goodreads URLs saved to books_with_goodreads_urls.xlsx\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from urllib.parse import quote_plus\n",
    "\n",
    "# # Function to get Goodreads URL based on book title and author\n",
    "# def get_goodreads_url(title, author):\n",
    "#     search_query = f\"{title} {author}\"\n",
    "#     url = f\"https://www.goodreads.com/search?q={quote_plus(search_query)}&search_type=authors\"\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#     # Find the first book result and return its URL\n",
    "#     try:\n",
    "#         book_link = soup.find('a', class_='bookTitle')['href']\n",
    "#         return f\"https://www.goodreads.com{book_link}\"\n",
    "#     except TypeError:\n",
    "#         return None\n",
    "\n",
    "# # Load the dataset from Excel\n",
    "# input_file = 'Goodreads.csv'  # Replace with your Excel file name\n",
    "# df = pd.read_csv(input_file)\n",
    "\n",
    "# # Ensure your Excel file has 'Title' and 'Author' columns\n",
    "# if 'Title' not in df.columns or 'Author' not in df.columns:\n",
    "#     raise ValueError(\"Excel file must contain 'Title' and 'Author' columns\")\n",
    "# # \n",
    "# # Apply the get_goodreads_url function to each row in the DataFrame\n",
    "# df['Goodreads_URL'] = df.apply(lambda row: get_goodreads_url(row['Title'], row['Author']), axis=1)\n",
    "\n",
    "# # Save the updated DataFrame with Goodreads URLs to a new Excel file\n",
    "# output_file = 'books_with_goodreads_urls.xlsx'  # Output file name\n",
    "# df.to_excel(output_file, index=False)\n",
    "\n",
    "# print(f\"Scraped Goodreads URLs saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues\n",
    "\n",
    "- no url loaded in the url column\n",
    "- scraping fails\n",
    "\n",
    "# Attempts to fix\n",
    "- Use selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# # Set up Selenium WebDriver\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')  # Run in headless mode\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# def get_goodreads_url(title, author):\n",
    "#     search_query = f\"{title} {author}\"\n",
    "#     url = f\"https://www.goodreads.com/search?q={quote_plus(search_query)}\"\n",
    "#     driver.get(url)\n",
    "\n",
    "#     try:\n",
    "#         # Find the first book link using XPath or CSS selectors\n",
    "#         book_link = driver.find_element(By.CSS_SELECTOR, 'a.bookTitle')\n",
    "#         return book_link.get_attribute('href')\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error scraping {title}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # After scraping, close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import time\n",
    "\n",
    "# df = pd.read_csv(r'Goodreads_PH.csv')\n",
    "\n",
    "# #set up chrome options \n",
    "# chrome_options = Options()\n",
    "# # chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "# # path to your chrome dirver\n",
    "# service = Service('chromedriver.exe')\n",
    "# driver = webdriver.Chrome(service = service, options=chrome_options)\n",
    "\n",
    "# results = []\n",
    "\n",
    "# try:\n",
    "\n",
    "#     for index, row in df.iterrows():\n",
    "#         title = row['Title']\n",
    "#         author = row['Author']\n",
    "        \n",
    "#         # open Goodreads\n",
    "#         driver.get(\"https://www.goodreads.com/\")\n",
    "        \n",
    "#         #find search box and enter the query\n",
    "#         search_box = driver.find_element(By.NAME, \"q\")\n",
    "#         search_box.send_keys(f\"{title} {author}\")\n",
    "#         search_box.send_keys(Keys.RETURN)\n",
    "        \n",
    "#         #Wait for results to load\n",
    "#         WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located((By.CSS_SELECTOR, \"a.bookTitle\"))\n",
    "#         )\n",
    "        \n",
    "#         #extract urls from search results\n",
    "#         search_results = driver.find_elements(By.CSS_SELECTOR, \"a.bookTitle\")\n",
    "#         for result in search_results:\n",
    "#             book_title = result.text\n",
    "#             book_url = result.get_attribute(\"href\")\n",
    "#             results.append({\"Title\": book_title, \"URL\": book_url})\n",
    "        \n",
    "# finally:\n",
    "#     #quit the driver\n",
    "#     driver.quit()\n",
    "\n",
    "# #convert results to df and save to csv\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv('book_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
